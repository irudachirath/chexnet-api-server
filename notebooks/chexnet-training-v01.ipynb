{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9223495,"sourceType":"datasetVersion","datasetId":5578105},{"sourceId":9223534,"sourceType":"datasetVersion","datasetId":5578133},{"sourceId":9224191,"sourceType":"datasetVersion","datasetId":5578590},{"sourceId":9224414,"sourceType":"datasetVersion","datasetId":5578740},{"sourceId":9238925,"sourceType":"datasetVersion","datasetId":5588523},{"sourceId":9243115,"sourceType":"datasetVersion","datasetId":5591333},{"sourceId":9243258,"sourceType":"datasetVersion","datasetId":5591427},{"sourceId":9243410,"sourceType":"datasetVersion","datasetId":5591524},{"sourceId":9243520,"sourceType":"datasetVersion","datasetId":5591598},{"sourceId":9243649,"sourceType":"datasetVersion","datasetId":5591689},{"sourceId":9249022,"sourceType":"datasetVersion","datasetId":5595306},{"sourceId":9249312,"sourceType":"datasetVersion","datasetId":5595523},{"sourceId":9249679,"sourceType":"datasetVersion","datasetId":5595795},{"sourceId":9250417,"sourceType":"datasetVersion","datasetId":5596314},{"sourceId":9250672,"sourceType":"datasetVersion","datasetId":5596494},{"sourceId":9250965,"sourceType":"datasetVersion","datasetId":5596701},{"sourceId":9252379,"sourceType":"datasetVersion","datasetId":5597701},{"sourceId":9317257,"sourceType":"datasetVersion","datasetId":5643478}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n#         print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-05T17:43:32.095282Z","iopub.execute_input":"2024-09-05T17:43:32.095635Z","iopub.status.idle":"2024-09-05T17:43:34.894635Z","shell.execute_reply.started":"2024-09-05T17:43:32.095598Z","shell.execute_reply":"2024-09-05T17:43:34.893660Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import roc_auc_score\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:43:34.896256Z","iopub.execute_input":"2024-09-05T17:43:34.896730Z","iopub.status.idle":"2024-09-05T17:43:40.810122Z","shell.execute_reply.started":"2024-09-05T17:43:34.896688Z","shell.execute_reply":"2024-09-05T17:43:40.809330Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Set constants\nN_CLASSES = 15\nCLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n               'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia', 'None_Of_these_diseases']\nDATA_DIR_TRAIN = '/kaggle/input/'\nDATA_DIR_VALID = '/kaggle/input/'\nTRAIN_IMAGE_LIST = '/kaggle/input/dataset-v3-0/training_only_labels.csv'\nVAL_IMAGE_LIST = '/kaggle/input/dataset-v3-0/testing_only_labels.csv'\nBATCH_SIZE = 64\nEPOCHS = 10\nLEARNING_RATE = 1e-4","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:43:40.841946Z","iopub.execute_input":"2024-09-05T17:43:40.842228Z","iopub.status.idle":"2024-09-05T17:43:40.853904Z","shell.execute_reply.started":"2024-09-05T17:43:40.842197Z","shell.execute_reply":"2024-09-05T17:43:40.852969Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_data = train_data.iloc[:, 1:]","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:43:41.852709Z","iopub.status.idle":"2024-09-05T17:43:41.853053Z","shell.execute_reply.started":"2024-09-05T17:43:41.852883Z","shell.execute_reply":"2024-09-05T17:43:41.852900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_distribution = train_data.sum()\nprint(\"Class Distribution:\\n\", class_distribution)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:43:41.854434Z","iopub.status.idle":"2024-09-05T17:43:41.854799Z","shell.execute_reply.started":"2024-09-05T17:43:41.854628Z","shell.execute_reply":"2024-09-05T17:43:41.854647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_distribution_dict = class_distribution.to_dict()\nclass_distribution_dict","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:43:41.855749Z","iopub.status.idle":"2024-09-05T17:43:41.856074Z","shell.execute_reply.started":"2024-09-05T17:43:41.855903Z","shell.execute_reply":"2024-09-05T17:43:41.855920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Creating a bar plot\nplt.figure(figsize=(10, 6))\nplt.bar(class_distribution_dict.keys(), class_distribution_dict.values(), color='skyblue')\nplt.xlabel('Disease')\nplt.ylabel('Number of Images')\nplt.title('Class Distribution of Diseases in the Training Data')\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:43:41.857360Z","iopub.status.idle":"2024-09-05T17:43:41.857728Z","shell.execute_reply.started":"2024-09-05T17:43:41.857549Z","shell.execute_reply":"2024-09-05T17:43:41.857569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# total_samples = sum(class_distribution_dict.values())\ntotal_samples = train_data.shape[0]\nprint(\"Total number of samples: \", total_samples)\nclass_weights_dict = {cls: total_samples / (len(class_distribution_dict) * freq) for cls, freq in class_distribution_dict.items()}\n\nprint(total_samples)\nprint(\"Class Weights:\\n\", class_weights_dict)\n\n# Convert weights to a tensor (order should match your class labels)\nclass_weights = torch.tensor(list(class_weights_dict.values()), dtype=torch.float)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:43:41.859043Z","iopub.status.idle":"2024-09-05T17:43:41.859394Z","shell.execute_reply.started":"2024-09-05T17:43:41.859215Z","shell.execute_reply":"2024-09-05T17:43:41.859233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Multiply each value in class_distribution_dict by the corresponding weight\nweighted_values = {key: class_distribution_dict[key] * class_weights_dict[key] for key in class_distribution_dict.keys()}\n\n# Creating the bar plot\nplt.figure(figsize=(10, 6))\nplt.bar(weighted_values.keys(), weighted_values.values(), color='skyblue')\nplt.xlabel('Disease')\nplt.ylabel('Weighted Number of Images')\nplt.title('Weighted Class Distribution of Diseases in the Training Data')\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:43:41.860719Z","iopub.status.idle":"2024-09-05T17:43:41.861042Z","shell.execute_reply.started":"2024-09-05T17:43:41.860881Z","shell.execute_reply":"2024-09-05T17:43:41.860897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ChestXrayDataSet(Dataset):\n    def __init__(self, data_dir, csv_file, transform=None):\n        \"\"\"\n        Args:\n            data_dir: path to the directory containing images.\n            csv_file: path to the CSV file containing image filenames and corresponding labels.\n            transform: optional transform to be applied on a sample.\n        \"\"\"\n        self.image_names = []\n        self.labels = []\n        start = True  # Using a boolean to control the header skip is more clear\n        with open(csv_file, \"r\") as f:\n            for line in f:\n                if start:\n                    start = False\n                    continue\n                items = line.strip().split(\",\")  # Using strip() to remove any trailing newline characters\n                image_name = items[0]\n                label = [int(i) for i in items[1:]]\n                image_path = self.find_image_path(data_dir, image_name)  # Adjusted to self.find_image_path\n                if image_path:  # Ensure the image path exists\n                    self.image_names.append(image_path)\n                    self.labels.append(label)\n\n        self.transform = transform\n\n    @staticmethod\n    def find_image_path(data_dir, image_name):\n        \"\"\"\n        Static method to find the path of an image given the data directory and the image name.\n        \"\"\"\n        for i in range(1, 12):  # Assuming there are six folders\n            folder_name = f'images-0{i}'\n            image_path = os.path.join(data_dir, folder_name, 'images', image_name)\n            if os.path.exists(image_path):\n                return image_path\n        return None  # Consider how you want to handle cases where the image isn't found\n\n    def __getitem__(self, index):\n        \"\"\"\n        Args:\n            index: the index of item\n\n        Returns:\n            image and its labels\n        \"\"\"\n        image_name = self.image_names[index]\n        image = Image.open(image_name).convert('RGB')\n        label = self.labels[index]\n        if self.transform is not None:\n            image = self.transform(image)\n        return image, torch.FloatTensor(label)\n\n    def __len__(self):\n        return len(self.image_names)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:43:41.862050Z","iopub.status.idle":"2024-09-05T17:43:41.862368Z","shell.execute_reply.started":"2024-09-05T17:43:41.862203Z","shell.execute_reply":"2024-09-05T17:43:41.862220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the model architecture\nclass DenseNet121(nn.Module):\n    \"\"\"Model modified for multi-label classification.\"\"\"\n    def __init__(self, out_size):\n        super(DenseNet121, self).__init__()\n        self.densenet121 = torchvision.models.densenet121(pretrained=True)\n        num_ftrs = self.densenet121.classifier.in_features\n        self.densenet121.classifier = nn.Sequential(\n            nn.Linear(num_ftrs, out_size),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.densenet121(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:43:41.865467Z","iopub.status.idle":"2024-09-05T17:43:41.865870Z","shell.execute_reply.started":"2024-09-05T17:43:41.865691Z","shell.execute_reply":"2024-09-05T17:43:41.865710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to compute AUCs\ndef compute_AUCs(gt, pred):\n    \"\"\"Computes Area Under the Curve (AUC) from prediction scores.\"\"\"\n    AUROCs = []\n    gt_np = gt.cpu().numpy()\n    pred_np = pred.cpu().numpy()\n    for i in range(N_CLASSES):\n        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n    return AUROCs","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:43:41.867120Z","iopub.status.idle":"2024-09-05T17:43:41.867476Z","shell.execute_reply.started":"2024-09-05T17:43:41.867299Z","shell.execute_reply":"2024-09-05T17:43:41.867318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Validation function\ndef validate(model, val_loader, criterion):\n    model.eval()\n    val_loss = 0.0\n    gt = torch.FloatTensor().cuda()\n    pred = torch.FloatTensor().cuda()\n\n    with torch.no_grad():\n        for i, (inputs, targets) in enumerate(val_loader):\n            inputs, targets = inputs.cuda(), targets.cuda()\n\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n\n            val_loss += loss.item()\n            gt = torch.cat((gt, targets), 0)\n            pred = torch.cat((pred, outputs), 0)\n\n    val_loss /= len(val_loader)\n    AUROCs = compute_AUCs(gt, pred)\n    val_auc = np.array(AUROCs).mean()\n\n    return val_loss, val_auc","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:43:41.868558Z","iopub.status.idle":"2024-09-05T17:43:41.868905Z","shell.execute_reply.started":"2024-09-05T17:43:41.868735Z","shell.execute_reply":"2024-09-05T17:43:41.868754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up the model\ncudnn.benchmark = True\n\nmodel = DenseNet121(out_size=N_CLASSES).cuda()\nmodel = torch.nn.DataParallel(model).cuda()\n\n# Define loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss(pos_weight=class_weights).cuda()\n# criterion = nn.BCELoss().cuda()\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n# Data augmentation and normalization for training\nnormalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:43:41.870821Z","iopub.status.idle":"2024-09-05T17:43:41.871156Z","shell.execute_reply.started":"2024-09-05T17:43:41.870990Z","shell.execute_reply":"2024-09-05T17:43:41.871007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = ChestXrayDataSet(data_dir=DATA_DIR_TRAIN,\n                                 csv_file=TRAIN_IMAGE_LIST,\n                                 transform=transforms.Compose([\n                                     transforms.Resize(256),\n                                     transforms.RandomResizedCrop(224),\n                                     transforms.RandomHorizontalFlip(),\n                                     transforms.ToTensor(),\n                                     normalize,\n                                 ]))","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:43:41.872037Z","iopub.status.idle":"2024-09-05T17:43:41.872366Z","shell.execute_reply.started":"2024-09-05T17:43:41.872199Z","shell.execute_reply":"2024-09-05T17:43:41.872216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE,\n                          shuffle=True, num_workers=3, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:43:41.875775Z","iopub.status.idle":"2024-09-05T17:43:41.876230Z","shell.execute_reply.started":"2024-09-05T17:43:41.875989Z","shell.execute_reply":"2024-09-05T17:43:41.876013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_dataset = ChestXrayDataSet(data_dir=DATA_DIR_VALID,\n                               csv_file=VAL_IMAGE_LIST,\n                               transform=transforms.Compose([\n                                   transforms.Resize(256),\n                                   transforms.CenterCrop(224),\n                                   transforms.ToTensor(),\n                                   normalize,\n                               ]))","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:43:41.877831Z","iopub.status.idle":"2024-09-05T17:43:41.878277Z","shell.execute_reply.started":"2024-09-05T17:43:41.878044Z","shell.execute_reply":"2024-09-05T17:43:41.878068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE,\n                        shuffle=False, num_workers=3, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:43:41.879989Z","iopub.status.idle":"2024-09-05T17:43:41.880468Z","shell.execute_reply.started":"2024-09-05T17:43:41.880205Z","shell.execute_reply":"2024-09-05T17:43:41.880230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training loop\nfor epoch in range(EPOCHS):\n    print(f'Epoch {epoch + 1}/{EPOCHS}')\n    model.train()\n    running_loss = 0.0\n\n    for i, (inputs, targets) in enumerate(train_loader):\n        inputs, targets = inputs.cuda(), targets.cuda()\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        if i % 10 == 9:  # Print every 10 batches\n            print(f'Batch {i + 1}, Loss: {running_loss / 10:.4f}')\n            running_loss = 0.0\n\n    # Validation after each epoch\n    val_loss, val_auc = validate(model, val_loader, criterion)\n    print(f'Validation Loss: {val_loss:.4f}, Validation AUC: {val_auc:.4f}')\n\n    # Save the model with the validation AUC in the filename\n    model_filename = f'chexnet_2nd_epoch_{epoch + 1}_auc_{val_auc:.4f}.pth'\n    torch.save(model.state_dict(), model_filename)\n    print(f'Model saved as {model_filename}')","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:43:41.881997Z","iopub.status.idle":"2024-09-05T17:43:41.882328Z","shell.execute_reply.started":"2024-09-05T17:43:41.882163Z","shell.execute_reply":"2024-09-05T17:43:41.882180Z"},"trusted":true},"execution_count":null,"outputs":[]}]}